# Classificador de Materiais Recicl√°veis

## üìå Vis√£o Geral

Este projeto apresenta uma solu√ß√£o de aprendizado de m√°quina, implementada em PyTorch, para realizar a classifica√ß√£o autom√°tica de imagens de res√≠duos recicl√°veis em quatro classes distintas: glass, metal, paper e plastic. Trata-se de um problema de classifica√ß√£o multiclasse, com foco em redes neurais convolucionais (CNNs) aplicadas √† Vis√£o Computacional.

A arquitetura do modelo foi encapsulada na classe Architecture, respons√°vel por organizar todo o pipeline de pr√©-processamento, treinamento, valida√ß√£o e infer√™ncia, com suporte a execu√ß√£o em GPU.

O projeto foi desenvolvido como parte da avalia√ß√£o final da disciplina PPGEEC2318 - Machine Learning ministrada pelo Prof. Dr. Ivanovitch Medeiros, do Programa de P√≥s-Gradua√ß√£o em Engenharia El√©trica e de Computa√ß√£o da UFRN.

## üìÇ Dataset

O conjunto de dados utilizado √© uma adapta√ß√£o do `TrashNet: A set of annotated images of trash that can be used for object detection Dataset`, desenvolvido pelo Polygence Project e disponibilizado na plataforma Roboflow.

Embora o dataset original contenha seis classes (cardboard, glass, metal, paper, plastic e trash), este projeto considera apenas as quatro categorias relacionadas √† coleta seletiva: glass, metal, paper e plastic.

Foram utilizadas 400 imagens de treinamento e 100 imagens de valida√ß√£o para cada classe, em que cada uma delas tem 512x384 pixels. A Figura a seguir cont√©m uma imagem de cada classe presente no dataset.

<p align="center">
  <img src="imagens/ex_imagens_dataset.png" alt="Exemplos de imagens presentes no dataset" width="450">
</p>

## Arquitetura e Desenvolvimento dos Modelos

A metodologia utilizada consistiu na implementa√ß√£o de dois modelos CNN (modelo base e modelo pessoal), buscando observar como altera√ß√µes na arquitetura e no learning rate afetam no desempenho da classifica√ß√£o.

### Modelo Base

Este modelo, implementado no arquivo `ClassifierModelBase.ipynb`, utiliza uma arquitetura baseada no material de aula disponibilizado pelo professor. No pr√©-processamento, as imagens passaram apenas pelas transforma√ß√µes essenciais de redimensionamento (para o tamanho esperado pela rede) e convers√£o para o formato de tensor PyTorch.

A arquitetura da rede consiste em uma CNN sequencial com a seguinte estrutura:

- Bloco Convolucional 1: Uma camada Conv2d com 16 filtros, seguida por uma fun√ß√£o de ativa√ß√£o ReLU e uma camada de MaxPool2d.
- Bloco Convolucional 2: Uma camada Conv2d com 32 filtros, tamb√©m seguida por ReLU e MaxPool2d.
- Classificador: Duas camadas lineares (Linear) para realizar a classifica√ß√£o final nas quatro categorias.

-> üîç Visualiza√ß√µes: Filtros e Hooks

Para entender o comportamento interno da rede, foram utilizados filtros e hooks. Os filtros da primeira camada convolucional (conv1), foram visualizados para inspecionar os tipos de caracter√≠sticas que o modelo aprendia a detectar nos est√°gios iniciais (ex: bordas, texturas e padr√µes simples). Ao passo que os filtros da segunda camada (conv2) aprendem a combinar essas caracter√≠sticas simples para identificar padr√µes mais complexos e abstratos, como texturas espec√≠ficas de cada material ou formas mais definidas. Tais filtros podem ser vistos adiante.

<p align="center"> <img src="imagens/modelobase/filter_conv1_modelbase.png" alt="FiltrosConv1" width="450"> </p>

<p align="center"> <img src="imagens/modelobase/filter_conv2_modelbase.png" alt="FiltrosConv2" width="450"> </p>

J√° os hooks foram utilizados para visualizar a transforma√ß√£o das imagens ao longo das camadas convolucionais, permitindo compreender o que cada camada aprende e como os filtros atuam sobre os dados. A seguir, s√£o apresentados, respectivamente, os feature maps extra√≠dos das camadas do featurizer (conv1, conv2) e do classifier (fc1, fc2).

<p align="center"> <img src="imagens/modelobase/features_map_convs_modelbase.png" alt="hook1" width="450"> </p>

<p align="center"> <img src="imagens/modelobase/features_map_classifier_modelbase.png" alt="hook2" width="450"> </p>

### Modelo Pessoal

Partindo da an√°lise do modelo anterior, foi desenvolvido o `ClassifierPersonalModel.ipynb`. Esta implementa√ß√£o aplica altera√ß√µes na prepara√ß√£o dos dados e na arquitetura da rede com o objetivo de construir uma rede mais robusta, capaz de aprender caracter√≠sticas mais detalhadas das imagens.

As principais modifica√ß√µes introduzidas foram:

- Aumento da Resolu√ß√£o da Imagem: O tamanho das imagens de entrada foi alterado de 28x28 para 128x128 pixels. Essa mudan√ßa √© fundamental, pois imagens com maior resolu√ß√£o cont√™m mais detalhes visuais. Para um problema de classifica√ß√£o de materiais, onde texturas sutis e padr√µes finos s√£o importantes para a diferencia√ß√£o (como o brilho do vidro ou a rugosidade do papel), fornecer mais pixels √† rede permite que as camadas convolucionais extraiam caracter√≠sticas mais ricas e discriminativas, potencializando a precis√£o do modelo.

- Prepara√ß√£o de Dados com Data Augmentation: Para aumentar a robustez e a capacidade de generaliza√ß√£o do modelo, foram aplicadas transforma√ß√µes aleat√≥rias nas imagens de treinamento, como RandomHorizontalFlip (espelhamento horizontal), RandomRotation (rota√ß√µes) e ColorJitter (altera√ß√µes de brilho, contraste e satura√ß√£o).

- Aumento da Complexidade da Arquitetura: O n√∫mero de filtros nas camadas convolucionais foi expandido progressivamente para permitir que a rede aprendesse padr√µes mais complexos a partir dos dados de maior resolu√ß√£o. A arquitetura conta com 3 camadas convolucionais, sendo a primeira com n_feature filtros, a segunda com n_feature * 2 filtros e a terceira com n_feature * 4 filtros. Essa configura√ß√£o amplia significativamente a capacidade da rede de extrair representa√ß√µes hier√°rquicas dos dados de entrada.

- Adi√ß√£o de Camadas de Regulariza√ß√£o e Estabiliza√ß√£o: Para gerenciar a maior complexidade da rede e mitigar o risco de overfitting, foram adicionadas camadas de BatchNorm2d ap√≥s cada convolu√ß√£o para estabilizar o treinamento, e camadas de Dropout nas etapas finais do classificador.

- Ado√ß√£o da t√©cnica de early stopping: Interrompe o treinamento automaticamente ao detectar estagna√ß√£o na valida√ß√£o, evitando sobreajuste e contribuindo para um modelo mais generaliz√°vel.

## üìä Resultados e Desempenho

Para o treinamento do Modelo Base, foi utilizado um n√∫mero inicial de 5 filtros na primeira camada convolucional. A fun√ß√£o de perda adotada foi a Cross-Entropy Loss (nn.CrossEntropyLoss), combinada com o otimizador Adam e uma taxa de aprendizado (learning rate) de 3e-4. O treinamento foi realizado ao longo de 10 √©pocas.

A figura a seguir apresenta a curva de perda durante o treinamento, mostrando a evolu√ß√£o das perdas de treinamento (em azul) e valida√ß√£o (em vermelho). Ambas iniciam com valores em torno de 1.37 e apresentam uma queda constante ao longo das √©pocas, alcan√ßando aproximadamente 1.18 ao final do processo. Esse comportamento indica um aprendizado est√°vel e sem overfitting. No entanto, os valores finais ainda relativamente altos sugerem que o Modelo Base possui limita√ß√µes na extra√ß√£o de padr√µes mais representativos, motivando o desenvolvimento de arquiteturas mais complexas nos modelos seguintes.

<p align="center"> <img src="imagens/modelobase/grafico_de_perdas_modelbase.png" alt="CurvaDePerda_modelbase" width="450"> </p>

Para o treinamento do Modelo Pessoal, foram utilizadas 32 features na primeira camada convolucional e taxa de dropout de 0.18, com o objetivo de aumentar a capacidade de generaliza√ß√£o da rede. A fun√ß√£o de perda adotada foi novamente a Cross-Entropy Loss com m√©dia (reduction='mean'), e o otimizador escolhido foi o Adam, agora com uma taxa de aprendizado ajustada para aproximadamente 7.35e-5 e regulariza√ß√£o L2 (weight decay) de 1e-4. O modelo foi treinado por 31 √©pocas.

Essa abordagem resultou em um modelo mais eficiente, com ganhos vis√≠veis na curva de perda. Dessa forma, a figura a seguir mostra que as perdas de treinamento e valida√ß√£o caem progressivamente at√© cerca da 15¬™ √©poca, atingindo valores em torno de 0.55. Ap√≥s esse ponto, a perda de valida√ß√£o apresenta certa oscila√ß√£o, sinalizando um in√≠cio de overfitting leve, mas ainda assim mant√©m desempenho superior ao modelo base. O comportamento geral da curva reflete um aprendizado mais consistente e uma maior capacidade de generaliza√ß√£o.

<p align="center"> <img src="imagens/modelobase/grafico_de_perdas_modelopessoal.png" alt="CurvaDePerda_modelopessoal" width="450"> </p>

Quanto √†s m√©tricas de desempenho, a tabela evidencia uma melhora significativa do modelo pessoal em rela√ß√£o ao modelo base, onde o primeiro atingiu cerca de 74% de acur√°cia, com precision, recall e f1-score mais equilibrados entre as classes, refletindo um desempenho mais consistente.

|                | **Accuracy** | **Precision** |  **Recall** | **F1-Score** |
|----------------|--------------|---------------|-------------|--------------|
| Modelo Base    |    50,75%    |     50,93%    |    50,75%   |    50,42%    |
| Modelo Pessoal |    74,75%    |     76,42%    |    74,75%   |    74,30%    |

As matrizes de confus√£o confirmam essa evolu√ß√£o, mostrando maior concentra√ß√£o de acertos na diagonal principal e redu√ß√£o nos erros de classifica√ß√£o. Isso indica que o modelo foi mais eficaz em distinguir corretamente entre as quatro classes.

<p align="center"> <img src="imagens/modelobase/matriz_confusao_modelbase.png" alt="matrizconf1" width="450"> </p>

<p align="center"> <img src="imagens/modelpessoal/matriz_confusao_modelopessoal.png" alt="matrizconf2" width="450"> </p>

Esses resultados comprovam que a nova arquitetura e a otimiza√ß√£o dos hiperpar√¢metros contribu√≠ram para uma melhor generaliza√ß√£o e precis√£o.

## An√°lise de Learning Rate

Para refinar ainda mais o "Modelo Pessoal", foi utilizada a t√©cnica Learning Rate Finder (LRFinder). O LRFinder treina o modelo por algumas itera√ß√µes, come√ßando com uma taxa de aprendizado (LR) muito baixa e aumentando-a exponencialmente a cada passo. Ao plotar a perda em fun√ß√£o do LR, √© poss√≠vel identificar a faixa de valores onde a perda diminui mais rapidamente, indicando uma taxa de aprendizado ideal. A imagem a seguir √© a gr√°fico do LR aplicado ao modelo pessoal.

<p align="center"> <img src="imagens/LRFinder/grafico_LRFinder.png" alt="lrf_findere" width="450"> </p>

Com base na sugest√£o do LRFinder o valor de learning rate 4.33e-04 foi selecionado e aplicado para treinar novamente o modelo. O desempenho desta nova vers√£o foi avaliado por meio do gr√°fico de perda e da matriz de confus√£o, apresentados a seguir.

<p align="center"> <img src="imagens/LRFinder/grafico_de_perdas_LRFinder.png" alt="lrf_finder2" width="450"> </p>

<p align="center"> <img src="imagens/LRFinder/matriz_confusao_LRFinder.png" alt="lrf_finder3" width="450"> </p>

Como √© poss√≠vel observas na imagens, a aplica√ß√£o da taxa de aprendizado sugerida pelo LRFinder resultou em um desempenho ligeiramente inferior ao do modelo com o learning rate ajustado manualmente.

## Conclus√£o

O desenvolvimento deste projeto evidenciou a import√¢ncia da escolha adequada de arquiteturas e da otimiza√ß√£o de hiperpar√¢metros no desempenho de modelos de classifica√ß√£o baseados em redes neurais. Por meio de ajustes no Modelo Pessoal, foi poss√≠vel alcan√ßar m√©tricas superiores em rela√ß√£o ao Modelo Base, demonstrando maior capacidade de generaliza√ß√£o e discrimina√ß√£o entre as classes.

Durante o processo de ajuste, foi utilizada a t√©cnica learning rate finder como alternativa para defini√ß√£o da taxa de aprendizado. Embora os resultados iniciais n√£o tenham sido os mais ideais neste caso espec√≠fico, a abordagem ainda se mostra v√°lida como ponto de partida para ajustes posteriores mais refinados.

## üîó Refer√™ncias

* [Roboflow - trashnet Computer Vision Project](https://universe.roboflow.com/myspace-uc4uq/trashnet-sn7pu)
* [Reposit√≥rio do Prof Dr. Ivanovitch](https://github.com/ivanovitchm/PPGEEC2318)

## üë• Colaboradores

* Adson Emanuel
* Klyfton Stanley
