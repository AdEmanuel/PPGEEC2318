# Classificador de Materiais Recicl√°veis

## üìå Vis√£o Geral

Este projeto apresenta uma solu√ß√£o de aprendizado de m√°quina, implementada em PyTorch, para realizar a classifica√ß√£o autom√°tica de imagens de res√≠duos recicl√°veis em quatro classes distintas: glass, metal, paper e plastic. Trata-se de um problema de classifica√ß√£o multiclasse, com foco em redes neurais convolucionais (CNNs) aplicadas √† Vis√£o Computacional.

A arquitetura do modelo foi encapsulada na classe Architecture, respons√°vel por organizar todo o pipeline de pr√©-processamento, treinamento, valida√ß√£o e infer√™ncia, com suporte a execu√ß√£o em GPU.

O projeto foi desenvolvido como parte da avalia√ß√£o final da disciplina PPGEEC2318 - Machine Learning ministrada pelo Prof. Dr. Ivanovitch Medeiros, do Programa de P√≥s-Gradua√ß√£o em Engenharia El√©trica e de Computa√ß√£o da UFRN.

## üìÇ Dataset

O conjunto de dados utilizado √© uma adapta√ß√£o do `TrashNet: A set of annotated images of trash that can be used for object detection Dataset`, desenvolvido pelo Polygence Project e disponibilizado na plataforma Roboflow.

Embora o dataset original contenha seis classes (cardboard, glass, metal, paper, plastic e trash), este projeto considera apenas as quatro categorias relacionadas √† coleta seletiva: glass, metal, paper e plastic.

Foram utilizadas 400 imagens de treinamento e 100 imagens de valida√ß√£o para cada classe, em que cada uma delas tem 512x384 pixels. A Figura a seguir cont√©m uma imagem de cada classe presente no dataset.

<p align="center"> <img src="Classificador Multiclasse de Materiais Recicl√°veis/imagens/ex_imagens_dataset.png.jpeg" alt="Exemplos de imagens presentes no dataset" width="450"> </p>

## Arquitetura e Desenvolvimento dos Modelos

A metodologia utilizada consistiu na implementa√ß√£o de dois modelos CNN (modelo base e modelo pessoal), buscando observar como altera√ß√µes na arquitetura e no learning rate afetam no desempenho da classifica√ß√£o.

### Modelo Base

Este modelo, implementado no arquivo ClassifierModelBase.ipynb, utiliza uma arquitetura baseada no material de aula disponibilizado pelo professor. No pr√©-processamento, as imagens passaram apenas pelas transforma√ß√µes essenciais de redimensionamento (para o tamanho esperado pela rede) e convers√£o para o formato de tensor PyTorch.

A arquitetura da rede consiste em uma CNN sequencial com a seguinte estrutura:

- Bloco Convolucional 1: Uma camada Conv2d com 16 filtros, seguida por uma fun√ß√£o de ativa√ß√£o ReLU e uma camada de MaxPool2d.
- Bloco Convolucional 2: Uma camada Conv2d com 32 filtros, tamb√©m seguida por ReLU e MaxPool2d.
- Classificador: Duas camadas lineares (Linear) para realizar a classifica√ß√£o final nas quatro categorias.

-> üîç Visualiza√ß√µes: Filtros e Hooks

Para entender o comportamento interno da rede, foram utilizados filtros e hooks. Os filtros da primeira camada convolucional (conv1), foram visualizados para inspecionar os tipos de caracter√≠sticas que o modelo aprendia a detectar nos est√°gios iniciais (ex: bordas, texturas e padr√µes simples). Ao passo que os filtros da segunda camada (conv2) aprendem a combinar essas caracter√≠sticas simples para identificar padr√µes mais complexos e abstratos, como texturas espec√≠ficas de cada material ou formas mais definidas.

<p align="center"> <img src="Classificador Multiclasse de Materiais Recicl√°veis/imagens/modelobase/filter_conv1_modelbase.png" alt="FiltrosConv1" width="450"> </p>

[IMAGEM DOS FILTROS DA CAMADA CONV1 DO MODELO BASE]
Figura: Visualiza√ß√£o dos 5 filtros da segunda camada convolucional do Modelo Base.

J√° os hooks foram utilizados para visualizar a transforma√ß√£o das imagens ao longo das camadas convolucionais, permitindo compreender o que cada camada aprende e como os filtros atuam sobre os dados. A seguir, s√£o apresentados os mapas de caracter√≠sticas (feature maps) extra√≠dos das camadas do featurizer (conv1, conv2) e do classifier (fc1, fc2).

### Modelo Pessoal

Partindo da an√°lise do modelo anterior, foi desenvolvido o ClassifierPersonalModel.ipynb. Este modelo representa aplica altera√ß√µes na prepara√ß√£o dos dados e na arquitetura da rede com o objetivo de construir uma rede mais robusta, capaz de aprender caracter√≠sticas mais detalhadas das imagens.

As principais modifica√ß√µes introduzidas neste modelo foram:

- Aumento da Resolu√ß√£o da Imagem: O tamanho das imagens de entrada foi alterado de 28x28 para 128x128 pixels. Essa mudan√ßa √© fundamental, pois imagens com maior resolu√ß√£o cont√™m mais detalhes visuais. Para um problema de classifica√ß√£o de materiais, onde texturas sutis e padr√µes finos s√£o importantes para a diferencia√ß√£o (como o brilho do vidro ou a rugosidade do papel), fornecer mais pixels √† rede permite que as camadas convolucionais extraiam caracter√≠sticas mais ricas e discriminativas, potencializando a precis√£o do modelo.

- Prepara√ß√£o de Dados com Data Augmentation: Para aumentar a robustez e a capacidade de generaliza√ß√£o do modelo, foram aplicadas transforma√ß√µes aleat√≥rias nas imagens de treinamento, como RandomHorizontalFlip (espelhamento horizontal), RandomRotation (rota√ß√µes) e ColorJitter (altera√ß√µes de brilho, contraste e satura√ß√£o).

- Aumento da Complexidade da Arquitetura: O n√∫mero de filtros nas camadas convolucionais foi expandido progressivamente para permitir que a rede aprendesse padr√µes mais complexos a partir dos dados de maior resolu√ß√£o. A arquitetura conta com 3 camadas convolucionais, sendo a primeira com n_feature filtros, a segunda com n_feature * 2 filtros e a terceira com n_feature * 4 filtros. Essa configura√ß√£o amplia significativamente a capacidade da rede de extrair representa√ß√µes hier√°rquicas dos dados de entrada.

- Adi√ß√£o de Camadas de Regulariza√ß√£o e Estabiliza√ß√£o: Para gerenciar a maior complexidade da rede e mitigar o risco de overfitting, foram adicionadas camadas de BatchNorm2d ap√≥s cada convolu√ß√£o para estabilizar o treinamento, e camadas de Dropout nas etapas finais do classificador.

## üìä Resultados e Desempenho

Para o treinamento do Modelo Base, foi utilizado um n√∫mero inicial de 5 filtros na primeira camada convolucional. A fun√ß√£o de perda adotada foi a Cross-Entropy Loss (nn.CrossEntropyLoss), combinada com o otimizador Adam e uma taxa de aprendizado (learning rate) de 3e-4. O treinamento foi realizado ao longo de 10 √©pocas.

A figura a seguir apresenta a curva de perda durante o treinamento, mostrando a evolu√ß√£o das perdas de treinamento (em azul) e valida√ß√£o (em vermelho). Ambas iniciam com valores em torno de 1.37 e apresentam uma queda constante ao longo das √©pocas, alcan√ßando aproximadamente 1.18 ao final do processo. Esse comportamento indica um aprendizado est√°vel e sem overfitting. No entanto, os valores finais ainda relativamente altos sugerem que o Modelo Base possui limita√ß√µes na extra√ß√£o de padr√µes mais representativos, motivando o desenvolvimento de arquiteturas mais complexas nos modelos seguintes.

[IMAGEM do gr√°fico de perdas]
Figura: Gr√°fico de perdas do modelo base.

Para o treinamento do Modelo Pessoal com Hiperpar√¢metros Otimizados, foram utilizadas 32 features na primeira camada convolucional e taxa de dropout de 0.18, com o objetivo de aumentar a capacidade de generaliza√ß√£o da rede. A fun√ß√£o de perda adotada foi novamente a Cross-Entropy Loss com m√©dia (reduction='mean'), e o otimizador escolhido foi o Adam, agora com uma taxa de aprendizado ajustada para aproximadamente 7.35e-5 e regulariza√ß√£o L2 (weight decay) de 1e-4. O modelo foi treinado por 31 √©pocas.

A escolha dos valores para n_feature, dropout e learning rate foi feita com o aux√≠lio da biblioteca Optuna, uma ferramenta de otimiza√ß√£o autom√°tica de hiperpar√¢metros baseada em estudos de tentativa e erro inteligentes (study-based optimization). O Optuna executa diversas combina√ß√µes poss√≠veis e utiliza algoritmos como Tree-structured Parzen Estimator (TPE) para identificar os melhores conjuntos de hiperpar√¢metros com base no desempenho do modelo em m√©tricas definidas.

Essa abordagem resultou em um modelo mais eficiente, com ganhos vis√≠veis tanto na curva de perda. Dessa forma, a figura mostra que as perdas de treinamento e valida√ß√£o caem progressivamente at√© cerca da 15¬™ √©poca, atingindo valores em torno de 0.55. Ap√≥s esse ponto, a perda de valida√ß√£o apresenta certa oscila√ß√£o, sinalizando um in√≠cio de overfitting leve, mas ainda assim mant√©m desempenho superior ao modelo base. O comportamento geral da curva reflete um aprendizado mais consistente e uma maior capacidade de generaliza√ß√£o.

[IMAGEM do gr√°fico de perdas]
Figura: Gr√°fico de perdas do modelo base.

Quanto √†s m√©tricas de desempenho, a tabela evidencia uma melhora significativa em rela√ß√£o ao modelo base. O Modelo Pessoal atingiu cerca de 74% de acur√°cia, com precision, recall e f1-score mais equilibrados entre as classes, refletindo um desempenho mais consistente.

TABELA

As matrizes de confus√£o confirmam essa evolu√ß√£o, mostrando maior concentra√ß√£o de acertos na diagonal principal e redu√ß√£o nos erros de classifica√ß√£o. Isso indica que o modelo foi mais eficaz em distinguir corretamente entre as quatro classes.

MATRIZES DE CONFUS√ÉO

Esses resultados comprovam que a nova arquitetura e a otimiza√ß√£o dos hiperpar√¢metros contribu√≠ram para uma melhor generaliza√ß√£o e precis√£o.

## An√°lise de Learning Rate

Para refinar ainda mais o "Modelo Pessoal", foi utilizada a t√©cnica Learning Rate Finder (LRFinder). O LRFinder treina o modelo por algumas itera√ß√µes, come√ßando com uma taxa de aprendizado (LR) muito baixa e aumentando-a exponencialmente a cada passo. Ao plotar a perda em fun√ß√£o do LR, √© poss√≠vel identificar a faixa de valores onde a perda diminui mais rapidamente, indicando uma taxa de aprendizado ideal. A imagem a seguir √© a gr√°fico do LR aplicado ao modelo pessoal.

Figura: Gr√°fico de Perda vs. Taxa de Aprendizado gerado pelo LRFinder.

Com base na sugest√£o do LRFinder o valor de learning rate 4.33e-04 foi selecionado e aplicado para treinar novamente o modelo. O desempenho desta nova vers√£o foi avaliado por meio do gr√°fico de perda e da matriz de confus√£o, apresentados a seguir.

FOTO LOSS FUNCTION E MATRIZ DE CONFUS√ÉO.

Como √© poss√≠vel observas na imagens, a aplica√ß√£o da taxa de aprendizado sugerida pelo LRFinder resultou em um desempenho ligeiramente inferior ao do modelo com o learning rate ajustado manualmente.

## Conclus√£o

## üîó Refer√™ncias

* [Roboflow - trashnet Computer Vision Project](https://universe.roboflow.com/myspace-uc4uq/trashnet-sn7pu)
* [Reposit√≥rio do Prof Dr. Ivanovitch](https://github.com/ivanovitchm/PPGEEC2318)

## üë• Colaboradores

* Adson Emanuel
* Klyfton Stanley
