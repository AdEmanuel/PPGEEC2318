# Customer Purchase Prediction - Binary Classification

## üìå Vis√£o Geral

Este projeto apresenta um modelo de aprendizado de m√°quina criado no PyTorch para prever a probabilidade de um cliente fazer uma compra, com base em caracter√≠sticas demogr√°ficas e comportamentais. Ele aborda um problema de classifica√ß√£o bin√°ria usando um conjunto de dados dispon√≠vel publicamente no Kaggle.

O modelo tem como objetivo ajudar as empresas a entender o comportamento do cliente e direcionar os poss√≠veis compradores de forma mais eficaz.

## üìÇ Dataset
- Fonte: [Kaggle - Predict Customer Purchase Behavior](https://www.kaggle.com/datasets/rabieelkharoua/predict-customer-purchase-behavior-dataset/data)
- Caracter√≠sticas:
  - Age: idade do cliente;
  - Gender: g√™nero do cliente (0: masculino, 1: feminino)
  - Annual Income: renda anual do cliente em d√≥lares
  - Number of Purchases: n√∫mero total de compras feitas pelo cliente
  - Product Category: categoria do produto comprado (0: Eletr√¥nicos, 1: Roupas, 2: Artigos para o lar, 3: Beleza, 4: Esportes)
  - Time Spent on Website: tempo gasto pelo cliente no site em minutos
  - Loyalty Program: se o cliente √© membro do programa de fidelidade (0: N√£o, 1: Sim)
  - Discounts Availed: n√∫mero de descontos aproveitados pelo cliente (intervalo: 0-5)
- Vari√°vel Alvo üéØ:
  - Purchase Status: probabilidade de o cliente fazer uma compra (0: N√£o, 1: Sim)

## üõ†Ô∏è Project Pipeline

O arquivo referente a etapa da EDA pode ser visto aqui: [eda.ipynb](https://github.com/AdEmanuel/PPGEEC2318/blob/main/Customer%20Purchase%20Behavior%20Prediction/eda.ipynb), ao passo que o arquivo 
contendo os passos descritos nas etapas 2, 3 e 4 √© o [purchase_classifier.ipynb](https://github.com/AdEmanuel/PPGEEC2318/blob/main/Customer%20Purchase%20Behavior%20Prediction/purchase_classifier.ipynb).

### 1. Exploratory Data Analysis (EDA)
Durante a etapa de An√°lise Explorat√≥ria dos Dados, observou-se que a vari√°vel-alvo (_Purchase Status_) apresenta um desbalanceamento entre as classes, o que poder√° influenciar negativamente o desempenho do modelo se n√£o for tratado adequadamente. Al√©m disso, verificou-se que as vari√°veis _Loyalty Program_ e _Discounts Availed_ demonstram maior correla√ß√£o com a vari√°vel de sa√≠da, indicando um impacto maior que as outras no comportamento de compra dos clientes.

No que diz respeito √†s vari√°veis num√©ricas, foi identificado que estas operam em escalas bastante distintas ‚Äî por exemplo, a vari√°vel _Annual Income_ varia aproximadamente entre 20.000 e 150.000, enquanto _Age_ apresenta valores entre 18 e 70. J√° entre as vari√°veis categ√≥ricas, a maioria apresenta duas categorias, com exce√ß√£o da vari√°vel _Product Category_, que cont√©m 5 classes distintas. Tais caracter√≠stica tornam necess√°rio o emprego de t√©cnicas de normaliza√ß√£o dos dados e codifica√ß√£o categ√≥rica.

### üìö 2. Dados de avalia√ß√£o

O conjunto de dados em estudo √© dividido em Train e Test durante o est√°gio Segregate do pipeline de dados. 80% dos dados limpos s√£o usados para treinar e os 20% restantes para testar. Al√©m disso, 20% dos dados do Train s√£o usados para fins de valida√ß√£o.

### üí™ 3. Treinamento

*3.1 Preprocessing and Tensor Preparation*

Antes do treinamento, os dados foram processados utilizando pipelines do Scikit-learn, com codifica√ß√£o one-hot aplicada √†s vari√°veis categ√≥ricas e normaliza√ß√£o padronizada para as vari√°veis num√©ricas. Em seguida, a t√©cnica SMOTE foi utilizada para balancear a vari√°vel alvo na base de treino. Os dados resultantes foram convertidos em tensores utilizando o PyTorch, sendo organizados em TensorDatasets e carregados em mini-lotes com o aux√≠lio da classe DataLoader.

*3.2 Model*

O modelo treinado √© uma rede neural simples configurada para tarefa de classifica√ß√£o bin√°ria. Sua estrutura est√° encapsulada na classe LogisticRegressionModel. A fun√ß√£o de perda utilizada foi BCEWithLogitsLoss e o otimizador escolhido foi o Adam, com taxa de aprendizado de 0.01.

*3.3 Training Framework*

A classe `Architecture` foi projetada para gerenciar de forma abrangente todas as etapas do processo de treinamento de modelos, incluindo a valida√ß√£o e o mecanismo de checkpointing. Ela encapsula as opera√ß√µes de propaga√ß√£o direta, retropropaga√ß√£o, atualiza√ß√£o dos pesos e c√°lculo das m√©tricas de desempenho, trabalhando diretamente com tensores e garantindo compatibilidade com execu√ß√£o em GPU.

Al√©m disso, ela oferece suporte para salvar e recuperar o estado do modelo ‚Äî incluindo os weights e os par√¢metros do otimizador ‚Äî, o que √© fundamental para garantir a reprodutibilidade dos resultados, permitir a retomada de treinamentos interrompidos e facilitar a posterior implanta√ß√£o do modelo treinado. 

No presente projeto, a classe foi utilizada para treinar o classificador ao longo de 100 √©pocas. A cada √©poca, o modelo era avaliado tanto nos dados de treino quanto nos dados de valida√ß√£o, possibilitando o monitoramento cont√≠nuo da aprendizagem e a mitiga√ß√£o de overfitting.

### üìä 4. Curva de Perda (Loss Curve) e M√©tricas de Desempenho

A curva de perda evidencia uma boa converg√™ncia ao longo das 100 √©pocas, com ambas as curvas ‚Äî de treino e de valida√ß√£o ‚Äî apresentando tend√™ncia de estabiliza√ß√£o ap√≥s aproximadamente 20 itera√ß√µes. A proximidade entre as curvas sugere que n√£o houve overfitting relevante, indicando um bom equil√≠brio entre aprendizado e generaliza√ß√£o.

<p align="center"> <img src="plot_losses.png" alt="Curvas de perdas" width="550"> </p>

Quanto √†s m√©tricas de desempenho, o modelo apresentou resultados satisfat√≥rios para uma tarefa de classifica√ß√£o bin√°ria:

|  M√©trica     | Valor   |
|--------------|---------|
| **Accuracy** | 85,14%  |
| **Precision**| 85,86%  |
| **Recall**   | 81,73%  |
| **F1-Score** | 83,74%  |

Esses indicadores refletem uma boa performance do modelo, o que √© corroborado pela an√°lise da matriz de confus√£o:

<p align="center"> <img src="confusion_matrix.png" alt="Matriz de Confus√£o" width="450"> </p>

Obesrva-se um bom n√∫mero de classifica√ß√µes corretas em rela√ß√£o √†s incorretas. Isso demonstra que o modelo √© eficaz tanto em identificar corretamente se o indiv√≠duo ir√° realizar uma compra (classe _Purchase_ ) quanto em evitar alarmes falsos (classe _No Purchase_).

Esses resultados s√£o ainda complementados pela curva ROC, cuja √°rea sob a curva (AUC = 0.8970) evidencia uma boa capacidade discriminativa, com a proximidade ao canto superior esquerdo do gr√°fico representando uma alta taxa de verdadeiros positivos com uma baixa taxa de falsos positivos:

<p align="center"> <img src="ROC_curve.png" alt="Curva ROC" width="450"> </p>

J√° a curva Precision-Recall mostra que o modelo mant√©m, em grande parte, uma precis√£o consistente mesmo com o aumento do recall, o que √© relevante em contextos com poss√≠vel desbalanceamento entre as classes:

<p align="center"> <img src="precision_recall_curve.png" alt="Curva Precision-Recall" width="450"> </p>

## Refer√™ncias

- [Kaggle - Predict Customer Purchase Behavior](https://www.kaggle.com/datasets/rabieelkharoua/predict-customer-purchase-behavior-dataset/data)
- [Reposit√≥rio do Prof Dr. Ivanovitch](https://github.com/ivanovitchm/PPGEEC2318)

## Colaboradores
- Adson Emanuel
- Klyfton Stanley

